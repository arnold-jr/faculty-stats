{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Science with Spark and Hadoop\n",
    "\n",
    "![A Hadoop stack](images/Hadoop_ecosystem.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Scala/Spark syntax and patterns\n",
    "1. The barrier to using Spark can be low\n",
    "1. All researchers can benefit from big data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analyzing Engineering Faculty Member Bios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"550\" \n",
       "src=\"http://engineering.vanderbilt.edu/people/\">\n",
       "</iframe>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe width=\"100%\" height=\"550\" \n",
    "src=\"http://engineering.vanderbilt.edu/people/\">\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tranform XML to JSON "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "```html\n",
    "<td>\n",
    "    <h4>\n",
    "        <a href=\"/bio/michael-alles\">Michael Alles</a>\n",
    "    </h4>\n",
    "    <br>\n",
    "    <strong>Intellectual Neighborhoods:</strong> \n",
    "    Risk and Reliability,Nano Science and Technology\n",
    "</td>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "```javascript\n",
    "{\n",
    "    \"name\":\"Michael Alles\",\n",
    "    \"focus\":\"\",\n",
    "    \"nhood\":\" Risk and Reliability,Nano Science and Technology\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```scala\n",
    "package faculty\n",
    "/**\n",
    "  * Created by joshuaarnold on 8/8/16.\n",
    "  */\n",
    "\n",
    "import common._\n",
    "import java.util.regex.Pattern\n",
    "\n",
    "import net.liftweb.json.JsonDSL._\n",
    "import net.liftweb.json._\n",
    "\n",
    "import scala.collection.breakOut\n",
    "import scala.reflect.ClassTag\n",
    "import scala.xml._\n",
    "\n",
    "object FacultyParsingSuite {\n",
    "\n",
    "  def parseEngineeringFaculty() = {\n",
    "\n",
    "    class Faculty(val name: String, val focus: String, val nhood: String) {\n",
    "\n",
    "      def getJson(): String = {\n",
    "        val json =\n",
    "          (\"name\" -> name) ~\n",
    "            (\"focus\" -> focus) ~\n",
    "            (\"nhood\" -> nhood)\n",
    "\n",
    "        compactRender(json)\n",
    "      }\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "    object Faculty {\n",
    "\n",
    "      def apply(node: Node) = {\n",
    "        def extract[T: ClassTag](t: T): List[String] = {\n",
    "          t match {\n",
    "            case n: Node => n match {\n",
    "              case <a>{_*}</a> => List(n text)\n",
    "              case <strong>{_*}</strong> => List(n text)\n",
    "              case <td>{_*}</td> => extract(n child)\n",
    "              case _ => extract(n child)\n",
    "            }\n",
    "            case s: Seq[Node@unchecked] => s match {\n",
    "              case Seq() => Nil\n",
    "              case Seq(x, xs@_*) => extract(x) ++ extract(xs)\n",
    "            }\n",
    "            case _ => throw new java.util.InputMismatchException(\"must be node \")\n",
    "          }\n",
    "        }\n",
    "\n",
    "        val keys = extract(node)\n",
    "\n",
    "        val keysRE = ((for {\n",
    "          k <- keys\n",
    "        } yield (Pattern quote k concat \"(.*)\")) mkString).r\n",
    "\n",
    "        val nKeys = keys length\n",
    "        val nodeText = node text\n",
    "        val fields = (for {\n",
    "          m <- keysRE.findAllIn(nodeText).matchData\n",
    "          g <- 1 to nKeys\n",
    "        } yield m.group(g)) toList\n",
    "\n",
    "        val dict: Map[String, String] = (keys zip fields)(breakOut)\n",
    "        val out = new Faculty(keys(0),\n",
    "          dict.getOrElse(\"Research Focus:\", \"\"),\n",
    "          dict.getOrElse(\"Intellectual Neighborhoods:\", \"\"))\n",
    "        out\n",
    "      }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    val fpath = \"/Users/joshuaarnold/Documents/MyApps/faculty-stats/resources\" +\n",
    "      \"/html/engineeringFaculty/engineeringFaculty.html\"\n",
    "    val elem = customParser.xmlToHtml.loadFile(fpath)\n",
    "\n",
    "    val tables = elem \\\\ \"table\" filter (x => (x \\ \"@id\" text) == \"peoplelisting\")\n",
    "\n",
    "    val meat = tables \\\\ \"tr\" \\\\ \"td\" filter (x => x \\ \"h4\" nonEmpty)\n",
    "\n",
    "    val jsonLines = meat map (x => Faculty(x)) map (_.getJson())\n",
    "\n",
    "    outputWriter(\"tmp/engineeringFaculty.json\", jsonLines)(x => x.concat(\"\\n\"))\n",
    "\n",
    "    jsonLines foreach println\n",
    "  }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def parseAllFaculty(fpath: String) = {\n",
    "\n",
    "\n",
    "    /**\n",
    "      * Parses the table element from a Degrees or Titles table\n",
    "      *\n",
    "      * @param tbody element containing sequence of <tr>\n",
    "      * @return Map[String, List[String]) of column header -> values\n",
    "      */\n",
    "    def parseTableBody(tbody: NodeSeq): Map[String, List[String]] = {\n",
    "\n",
    "      val trs = tbody \\\\ \"tr\"\n",
    "\n",
    "      // Stores all th and td values in column major order and transposes\n",
    "      val values = (for {\n",
    "        tr <- trs\n",
    "        if tr \\\\ \"td\" nonEmpty\n",
    "      } yield (tr \\\\ \"td\" toList) map (_ text) ) toList\n",
    "\n",
    "      val cols = (for {\n",
    "        th <- trs \\\\ \"th\"\n",
    "      } yield th.text) toList\n",
    "\n",
    "      val lists = (cols :: values) transpose\n",
    "\n",
    "      val acc0: Map[String, List[String]] = Map()\n",
    "      val maps =\n",
    "        (lists map {\n",
    "          case List() => Map()\n",
    "          case x :: xs => Map(x.toLowerCase() -> xs)\n",
    "        }).foldLeft(acc0)(_ ++ _)\n",
    "      maps\n",
    "    }\n",
    "\n",
    "    def extract[T: ClassTag](t: T): Map[String, List[String]] = {\n",
    "      t match {\n",
    "        case n: Node => {\n",
    "          val id = (n \\ \"@id\" text)\n",
    "          n match {\n",
    "            case <span>{ s }</span> => id match {\n",
    "              case \"ctl00_ContentPlaceHolder1_dlFaculty_ctl00_lblName\" =>\n",
    "                Map(\"name\" -> List(s.text))\n",
    "              case \"ctl00_ContentPlaceHolder1_dlFaculty_ctl00_Label2\" =>\n",
    "                Map(\"year\" -> List(s.text))\n",
    "              case _ =>\n",
    "                Map()\n",
    "            }\n",
    "            case <table>{ _* }</table> => parseTableBody(n)\n",
    "            case _ => extract(n child)\n",
    "          }\n",
    "        }\n",
    "        case s: Seq[Node@unchecked] => s match {\n",
    "          case Seq() => Map()\n",
    "          case Seq(x, xs@_*) => extract(x) ++ extract(xs)\n",
    "        }\n",
    "        case _ => throw new java.util.InputMismatchException(\"must be node \")\n",
    "      }\n",
    "    }\n",
    "\n",
    "    def parseOuterTable(outerTable: NodeSeq): String = {\n",
    "      val jin = extract(outerTable) map { case (s, xs) =>\n",
    "        if (xs.length == 1)\n",
    "          (s, xs.head) else (s, xs) }\n",
    "\n",
    "      val (a, b) = extract(outerTable) partition(_._2.length==1)\n",
    "\n",
    "      val j1 = parse(compactRender(a map {case (s, xs) => (s, xs.head)}))\n",
    "      val j2 = parse(compactRender(b))\n",
    "\n",
    "      val out = compactRender(j1 merge j2)\n",
    "\n",
    "      out\n",
    "    }\n",
    "\n",
    "    val customParser =\n",
    "      XML.withSAXParser(new org.ccil.cowan.tagsoup.jaxp.SAXFactoryImpl()\n",
    "        .newSAXParser())\n",
    "\n",
    "    val elem = customParser.loadFile(fpath)\n",
    "\n",
    "    val tables = elem \\\\ \"table\" filter (x => (x \\ \"@id\" text)\n",
    "      == \"ctl00_ContentPlaceHolder1_dlFaculty\")\n",
    "\n",
    "    val rows = tables \\\\ \"tr\"\n",
    "\n",
    "    val jsonLines = rows map parseOuterTable filterNot (_ == \"{}\")\n",
    "\n",
    "    outputWriter(\"tmp/allFaculty.json\", jsonLines)(x => x.concat(\"\\n\"))\n",
    "  }\n",
    "\n",
    "\n",
    "  object customParser {\n",
    "    val xmlToHtml =\n",
    "      XML.withSAXParser(new org.ccil.cowan.tagsoup.jaxp.SAXFactoryImpl()\n",
    "        .newSAXParser())\n",
    "  }\n",
    "\n",
    "\n",
    "  def main(args: Array[String]): Unit = {\n",
    "    // parseEngineeringFaculty()\n",
    "\n",
    "\n",
    "    val fpath = \"/Users/joshuaarnold/Documents/MyApps/faculty-stats/resources\" +\n",
    "      \"/html/allFaculty/A_names.html\"\n",
    "\n",
    "    parseAllFaculty(fpath)\n",
    "  }\n",
    "\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Word2Vec Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "val sqlc = sqlContext\n",
    "import sqlc.implicits._\n",
    "val facultyDF = sqlc.read.json(\"tmp/engineeringFaculty.json\")\n",
    "facultyDF.registerTempTable(\"faculty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------------------+-------------------+--------------------+\n",
       "|               focus|               name|               nhood|\n",
       "+--------------------+-------------------+--------------------+\n",
       "| Risk management,...|      Mark Abkowitz| Risk and Reliabi...|\n",
       "| Nonlinear struct...|      Douglas Adams| Risk and Reliabi...|\n",
       "| Human-System Int...|     Julie A. Adams| Cyber Physical S...|\n",
       "|         Development|     Nicholas Adams|                    |\n",
       "|                    |      Michael Alles| Risk and Reliabi...|\n",
       "| Magnetic resonan...|      Adam Anderson| Biomedical Imagi...|\n",
       "| Drop dynamics, a...|    A. V. Anilkumar| Energy and Natur...|\n",
       "|                    |     Theodore Bapty|                    |\n",
       "| Solar energy con...|      Rizia Bardhan| Regenerative Med...|\n",
       "| Welding and weld...|Robert Joel Barnett| Energy and Natur...|\n",
       "+--------------------+-------------------+--------------------+\n",
       "only showing top 10 rows\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%SQL\n",
    "SELECT * FROM faculty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Select and transform input data using SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               focus|\n",
      "+--------------------+\n",
      "|[Risk, management...|\n",
      "|[Nonlinear, struc...|\n",
      "|[Human, System, I...|\n",
      "|       [Development]|\n",
      "|[Magnetic, resona...|\n",
      "|[Drop, dynamics, ...|\n",
      "|[Solar, energy, c...|\n",
      "|[Welding, and, we...|\n",
      "|[Dynamic, systems...|\n",
      "|[Multiscale, beha...|\n",
      "|[Bioinstrumentati...|\n",
      "|[Microfluidics, m...|\n",
      "|[Tech, based, ent...|\n",
      "|[Technology, stra...|\n",
      "|[Computer, aided,...|\n",
      "|[Modeling, and, a...|\n",
      "|[Radiation, effec...|\n",
      "|[Virtual, Environ...|\n",
      "|[nanoscience, gra...|\n",
      "|[Information, pro...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val focusDF = sqlc.sql(\"SELECT focus FROM faculty WHERE LENGTH(focus)>0\")\n",
    "\n",
    "// Transform String to Tuple1[List[String]]\n",
    "val focusSplitDF = focusDF.map(r => Tuple1(r(0).toString\n",
    "  .replaceAll(\"\"\"[\\p{Punct}]\"\"\",\" \").split(\"\\\\s+\").filterNot(_ == \"\"))\n",
    ").toDF(\"focus\")\n",
    "\n",
    "focusSplitDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use Word2Vec to Find Synonyms in Research Focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "|           word|          similarity|\n",
      "+---------------+--------------------+\n",
      "|      Hydrology|0.009062745917056093|\n",
      "|      signaling|0.007882261001329424|\n",
      "|       Modeling|0.007774564754125474|\n",
      "|     underwater|0.007724221027430538|\n",
      "|       spectral|0.007616483427429222|\n",
      "|        antigen|0.007540289727149277|\n",
      "|    distributed|0.007514163031044968|\n",
      "|        welding|0.007366753454299188|\n",
      "|         Secure|0.007362351015667...|\n",
      "|      appraisal|0.007210608123060892|\n",
      "|        display|0.007104453107582285|\n",
      "|  environmental| 0.00675192222738749|\n",
      "|           path|0.006719895624075037|\n",
      "|      batteries|0.006464656359015513|\n",
      "|        cardiac|0.006458926007323657|\n",
      "|electrochemical|0.006457020772064...|\n",
      "|       Computer|0.006418360492989414|\n",
      "|          Raman|0.006353728381891622|\n",
      "|       learning|0.006349404061198687|\n",
      "|       recovery|0.006339612316653455|\n",
      "+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.{Word2Vec, StopWordsRemover}\n",
    "\n",
    "// Remove stop words\n",
    "val remover = new StopWordsRemover().setInputCol(\"focus\").setOutputCol(\"filtered\")\n",
    "val dataSet = remover.transform(focusSplitDF)\n",
    "\n",
    "// Learn a mapping from words to Vectors\n",
    "val word2Vec = (new Word2Vec()\n",
    "  .setInputCol(\"filtered\")aa\n",
    "  .setOutputCol(\"result\")\n",
    "  .setVectorSize(100)\n",
    "  .setMinCount(0))\n",
    "val model = word2Vec.fit(dataSet)\n",
    "val resultDF = model.findSynonyms(\"data\", 50)\n",
    "\n",
    "resultDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The MapReduce Framework\n",
    "\n",
    "![mapreduce](images/MapReduce_Work_Structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analyze all faculty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"550\" \n",
       "src=\"http://virg.vanderbilt.edu/webtools/registry/FacDetail.aspx?fname=&lname=A&school=0&dept=0\">\n",
       "</iframe>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe width=\"100%\" height=\"550\" \n",
    "src=\"http://virg.vanderbilt.edu/webtools/registry/FacDetail.aspx?fname=&lname=A&school=0&dept=0\">\n",
    "</iframe>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
